<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A programming framework for agentic AI"><meta name=author content="Chi Wang & Qingyun Wu"><link href=https://docs.ag2.ai/latest/docs/user-guide/reference-tools/wikipedia-search/ rel=canonical><link href=../perplexity-search/ rel=prev><link href=../browser-use/ rel=next><link rel=icon href=../../../../assets/img/favicon.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.9"><title>Wikipedia Search Tools - AG2</title><link rel=stylesheet href=../../../../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../../css/timeago.css><link rel=stylesheet href=../../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../../stylesheets/extra.e620a9.min.css><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2GN2KN2CE4"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2GN2KN2CE4",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2GN2KN2CE4",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta http-equiv=Cache-Control content="no-cache, no-store, must-revalidate"><meta property=og:type content=website><meta property=og:title content="AG2 - Wikipedia Search Tools"><meta property=og:description content="A programming framework for agentic AI"><meta content=https://docs.ag2.ai/latest/docs/user-guide/reference-tools/wikipedia-search/ property=og:url><meta property=og:image content=https://opengraph.githubassets.com/1671805243.560327/ag2ai/ag2><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="AG2 - Wikipedia Search Tools"><meta name=twitter:description content="A programming framework for agentic AI"><meta name=twitter:image content=https://opengraph.githubassets.com/1671805243.560327/ag2ai/ag2><link href=../../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=custom data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#package-installation class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> <aside class="md-banner md-banner--warning"> <div class="md-banner__inner md-grid md-typeset"> You're not viewing the latest version. <a href=../../../../..> <strong>Click here to go to latest.</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../../../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../.. title=AG2 class="md-header__button md-logo" aria-label=AG2 data-md-component=logo> <img src=../../../../assets/img/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AG2 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Wikipedia Search Tools </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=custom data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=custom data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ag2ai/ag2 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> ag2ai/ag2 </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../basic-concepts/installing-ag2/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../use-cases/use-cases/customer-service/ class=md-tabs__link> Use Cases </a> </li> <li class=md-tabs__item> <a href=../../../api-reference/autogen/AfterWork/ class=md-tabs__link> API References </a> </li> <li class=md-tabs__item> <a href=../../../user-stories/2025-02-11-NOVA/nova/ class=md-tabs__link> User Stories </a> </li> <li class=md-tabs__item> <a href=../../../contributor-guide/contributing/ class=md-tabs__link> Contributor Guide </a> </li> <li class=md-tabs__item> <a href=../../../faq/FAQ/ class=md-tabs__link> FAQs </a> </li> <li class=md-tabs__item> <a href=../../../ecosystem/agentops/ class=md-tabs__link> Ecosystem </a> </li> <li class=md-tabs__item> <a href=../../../blog class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../.. title=AG2 class="md-nav__button md-logo" aria-label=AG2 data-md-component=logo> <img src=../../../../assets/img/logo.svg alt=logo> </a> AG2 </label> <div class=md-nav__source> <a href=https://github.com/ag2ai/ag2 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> ag2ai/ag2 </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> User Guide </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../basic-concepts/installing-ag2/ class=md-nav__link> <span class=md-ellipsis> Basic Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../advanced-concepts/rag/ class=md-nav__link> <span class=md-ellipsis> Advanced Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../models/amazon-bedrock/ class=md-nav__link> <span class=md-ellipsis> Model Providers </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../reference-agents/ class=md-nav__link> <span class=md-ellipsis> Reference Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Reference Tools </span> </a> <label class="md-nav__link " for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=true> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> Reference Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../google-api/youtube-search/ class=md-nav__link> <span class=md-ellipsis> Google APIs </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../perplexity-search/ class=md-nav__link> <span class=md-ellipsis> Perplexity Search </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Wikipedia Search </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Wikipedia Search </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#package-installation class=md-nav__link> <span class=md-ellipsis> Package Installation </span> </a> </li> <li class=md-nav__item> <a href=#implementation class=md-nav__link> <span class=md-ellipsis> Implementation </span> </a> <nav class=md-nav aria-label=Implementation> <ul class=md-nav__list> <li class=md-nav__item> <a href=#imports class=md-nav__link> <span class=md-ellipsis> Imports </span> </a> </li> <li class=md-nav__item> <a href=#agent-configuration class=md-nav__link> <span class=md-ellipsis> Agent Configuration </span> </a> </li> <li class=md-nav__item> <a href=#wikipedia-query-run-tool-setup class=md-nav__link> <span class=md-ellipsis> Wikipedia Query Run Tool Setup </span> </a> </li> <li class=md-nav__item> <a href=#usage-example class=md-nav__link> <span class=md-ellipsis> Usage Example </span> </a> </li> <li class=md-nav__item> <a href=#usage-example_1 class=md-nav__link> <span class=md-ellipsis> Usage Example </span> </a> </li> <li class=md-nav__item> <a href=#output class=md-nav__link> <span class=md-ellipsis> Output </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../browser-use/ class=md-nav__link> <span class=md-ellipsis> Browser Use </span> </a> </li> <li class=md-nav__item> <a href=../deep-research/ class=md-nav__link> <span class=md-ellipsis> Deep Research </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../communication-platforms/discord/ class=md-nav__link> <span class=md-ellipsis> Communication Platforms </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../crawl4ai/ class=md-nav__link> <span class=md-ellipsis> Crawl4Ai </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../use-cases/use-cases/customer-service/ class=md-nav__link> <span class=md-ellipsis> Use Cases </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../api-reference/autogen/AfterWork/ class=md-nav__link> <span class=md-ellipsis> API References </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../user-stories/2025-02-11-NOVA/nova/ class=md-nav__link> <span class=md-ellipsis> User Stories </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../contributor-guide/contributing/ class=md-nav__link> <span class=md-ellipsis> Contributor Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../faq/FAQ/ class=md-nav__link> <span class=md-ellipsis> FAQs </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../ecosystem/agentops/ class=md-nav__link> <span class=md-ellipsis> Ecosystem </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../blog class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#package-installation class=md-nav__link> <span class=md-ellipsis> Package Installation </span> </a> </li> <li class=md-nav__item> <a href=#implementation class=md-nav__link> <span class=md-ellipsis> Implementation </span> </a> <nav class=md-nav aria-label=Implementation> <ul class=md-nav__list> <li class=md-nav__item> <a href=#imports class=md-nav__link> <span class=md-ellipsis> Imports </span> </a> </li> <li class=md-nav__item> <a href=#agent-configuration class=md-nav__link> <span class=md-ellipsis> Agent Configuration </span> </a> </li> <li class=md-nav__item> <a href=#wikipedia-query-run-tool-setup class=md-nav__link> <span class=md-ellipsis> Wikipedia Query Run Tool Setup </span> </a> </li> <li class=md-nav__item> <a href=#usage-example class=md-nav__link> <span class=md-ellipsis> Usage Example </span> </a> </li> <li class=md-nav__item> <a href=#usage-example_1 class=md-nav__link> <span class=md-ellipsis> Usage Example </span> </a> </li> <li class=md-nav__item> <a href=#output class=md-nav__link> <span class=md-ellipsis> Output </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/ag2ai/ag2/edit/main/website/docs/user-guide/reference-tools/wikipedia-search.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m7 14.94 6.06-6.06 2.06 2.06L9.06 17H7zM12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m4.7-10.65-1 1-2.05-2.05 1-1c.21-.22.56-.22.77 0l1.28 1.28c.22.21.22.56 0 .77M12 2a10 10 0 0 1 10 10 10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2"/></svg> </a> <h1>Wikipedia Search</h1> <p>The Wikipedia search integration allows users to perform search in wikipedia pages within the AG2 framework. Follow these steps to integrate Wikipedia Tools with AG2 Agents.</p> <h2 id=package-installation>Package Installation<a class=headerlink href=#package-installation title="Permanent link">#</a></h2> <p>To get started with the <code>Wikipedia Search</code> integration in AG2, follow these steps:</p> <p>Install AG2 with <code>"wikipedia</code> and <code>openai</code> since we use OpenAI's LLMs in our example:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>pip<span class=w> </span>install<span class=w> </span>-U<span class=w> </span><span class=s2>&quot;ag2[wikipedia, openai]&quot;</span>
</code></pre></div> <blockquote> <p><strong>Note:</strong> If you have been using <code>autogen</code> or <code>pyautogen</code>, all you need to do is upgrade it using: <div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>pip<span class=w> </span>install<span class=w> </span>-U<span class=w> </span><span class=s2>&quot;autogen[wikipedia, openai]&quot;</span>
</code></pre></div> or <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>pip<span class=w> </span>install<span class=w> </span>-U<span class=w> </span><span class=s2>&quot;pyautogen[wikipedia, openai]&quot;</span>
</code></pre></div> as <code>pyautogen</code>, <code>autogen</code>, and <code>ag2</code> are aliases for the same PyPI package.</p> </blockquote> <p>You're all set! Now you can start using Wikipedia Search with AG2.</p> <h2 id=implementation>Implementation<a class=headerlink href=#implementation title="Permanent link">#</a></h2> <h3 id=imports>Imports<a class=headerlink href=#imports title="Permanent link">#</a></h3> <div class=highlight><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
<a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>import</span><span class=w> </span><span class=nn>autogen</span>
<a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=kn>from</span><span class=w> </span><span class=nn>autogen</span><span class=w> </span><span class=kn>import</span> <span class=n>AssistantAgent</span><span class=p>,</span> <span class=n>UserProxyAgent</span><span class=p>,</span> <span class=n>LLMConfig</span>
<a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=kn>from</span><span class=w> </span><span class=nn>autogen.tools.experimental</span><span class=w> </span><span class=kn>import</span> <span class=n>WikipediaQueryRunTool</span><span class=p>,</span> <span class=n>WikipediaPageLoadTool</span>
</code></pre></div> <h3 id=agent-configuration>Agent Configuration<a class=headerlink href=#agent-configuration title="Permanent link">#</a></h3> <p>Configure an assistant agent and user proxy to be used for LLM recommendation and execution respectively.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=n>llm_config</span> <span class=o>=</span> <span class=n>LLMConfig</span><span class=p>(</span><span class=n>api_type</span><span class=o>=</span><span class=s2>&quot;openai&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&quot;gpt-4o-mini&quot;</span><span class=p>)</span>
<a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
<a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=n>assistant</span> <span class=o>=</span> <span class=n>AssistantAgent</span><span class=p>(</span>
<a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    <span class=n>name</span><span class=o>=</span><span class=s2>&quot;assistant&quot;</span><span class=p>,</span>
<a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>llm_config</span><span class=o>=</span><span class=n>llm_config</span><span class=p>,</span>
<a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=p>)</span>
<a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
<a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=n>user_proxy</span> <span class=o>=</span> <span class=n>UserProxyAgent</span><span class=p>(</span>
<a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=n>name</span><span class=o>=</span><span class=s2>&quot;user_proxy&quot;</span><span class=p>,</span>
<a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>human_input_mode</span><span class=o>=</span><span class=s2>&quot;NEVER&quot;</span>
<a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=p>)</span>
</code></pre></div> <h3 id=wikipedia-query-run-tool-setup>Wikipedia Query Run Tool Setup<a class=headerlink href=#wikipedia-query-run-tool-setup title="Permanent link">#</a></h3> <div class=highlight><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>wikipedia_tool</span> <span class=o>=</span> <span class=n>WikipediaQueryRunTool</span><span class=p>(</span><span class=n>top_k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
<a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
<a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Register the tool for LLM recommendation and execution.</span>
<a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>wikipedia_tool</span><span class=o>.</span><span class=n>register_for_llm</span><span class=p>(</span><span class=n>assistant</span><span class=p>)</span>
<a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>wikipedia_tool</span><span class=o>.</span><span class=n>register_for_execution</span><span class=p>(</span><span class=n>user_proxy</span><span class=p>)</span>
</code></pre></div> <h3 id=usage-example>Usage Example<a class=headerlink href=#usage-example title="Permanent link">#</a></h3> <p>With the setup complete, you can now use the assistant to fetch wikipedia search results.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=n>response</span> <span class=o>=</span> <span class=n>user_proxy</span><span class=o>.</span><span class=n>initiate_chat</span><span class=p>(</span>
<a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=n>recipient</span><span class=o>=</span><span class=n>assistant</span><span class=p>,</span>
<a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=n>message</span><span class=o>=</span><span class=s2>&quot;Who is the father of AI?&quot;</span><span class=p>,</span>
<a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=n>max_turns</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=p>)</span>
<a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=err>````</span>
<a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>
<a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=c1>### Output</span>
<a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>
<a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a><span class=err>```</span><span class=n>console</span>
<a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=n>user_proxy</span> <span class=p>(</span><span class=n>to</span> <span class=n>assistant</span><span class=p>):</span>
<a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>
<a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=o>*****</span> <span class=n>Response</span> <span class=kn>from</span><span class=w> </span><span class=nn>calling</span> <span class=n>tool</span> <span class=p>(</span><span class=n>call_u4fA2JLRY33JRhZAhjPIWz0A</span><span class=p>)</span> <span class=o>*****</span>
<a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a><span class=p>[</span><span class=s1>&#39;Page: Artificial intelligence</span><span class=se>\n</span><span class=s1>Summary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.</span><span class=se>\n</span><span class=s1>High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: &quot;A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it</span><span class=se>\&#39;</span><span class=s1>s not labeled AI anymore.&quot;</span><span class=se>\n</span><span class=s1>Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field</span><span class=se>\&#39;</span><span class=s1>s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.</span><span class=se>\n</span><span class=s1>Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.&#39;</span><span class=p>,</span>
<a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a> <span class=s1>&#39;Page: Dartmouth workshop</span><span class=se>\n</span><span class=s1>Summary: The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as &quot;the Constitutional Convention of AI&quot;. The project</span><span class=se>\&#39;</span><span class=s1>s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.</span><span class=se>\n</span><span class=s1>The project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.&#39;</span><span class=p>]</span>
<a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=o>**********************************************************************</span>
<a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>
<a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a><span class=o>--------------------------------------------------------------------------------</span>
<a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=n>assistant</span> <span class=p>(</span><span class=n>to</span> <span class=n>user_proxy</span><span class=p>):</span>
<a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>
<a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=n>The</span> <span class=n>term</span> <span class=s2>&quot;father of AI&quot;</span> <span class=n>typically</span> <span class=n>refers</span> <span class=n>to</span> <span class=n>several</span> <span class=n>key</span> <span class=n>figures</span> <span class=n>who</span> <span class=n>played</span> <span class=n>significant</span> <span class=n>roles</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>development</span> <span class=n>of</span> <span class=n>artificial</span> <span class=n>intelligence</span> <span class=k>as</span> <span class=n>a</span> <span class=n>field</span><span class=o>.</span> <span class=n>The</span> <span class=n>main</span> <span class=n>contributors</span> <span class=n>considered</span> <span class=k>as</span> <span class=n>the</span> <span class=n>founding</span> <span class=n>fathers</span> <span class=n>of</span> <span class=n>AI</span> <span class=n>include</span><span class=p>:</span>
<a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>
<a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=mf>1.</span> <span class=o>**</span><span class=n>John</span> <span class=n>McCarthy</span><span class=o>**</span> <span class=o>-</span> <span class=n>Often</span> <span class=n>credited</span> <span class=k>with</span> <span class=n>coining</span> <span class=n>the</span> <span class=n>term</span> <span class=s2>&quot;artificial intelligence&quot;</span> <span class=ow>and</span> <span class=n>organizing</span> <span class=n>the</span> <span class=n>Dartmouth</span> <span class=n>Workshop</span> <span class=ow>in</span> <span class=mi>1956</span><span class=p>,</span> <span class=n>which</span> <span class=ow>is</span> <span class=n>considered</span> <span class=n>the</span> <span class=n>founding</span> <span class=n>event</span> <span class=n>of</span> <span class=n>AI</span><span class=o>.</span>
<a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a><span class=mf>2.</span> <span class=o>**</span><span class=n>Marvin</span> <span class=n>Minsky</span><span class=o>**</span> <span class=o>-</span> <span class=n>A</span> <span class=n>pioneer</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>field</span> <span class=ow>and</span> <span class=n>co</span><span class=o>-</span><span class=n>organizer</span> <span class=n>of</span> <span class=n>the</span> <span class=n>Dartmouth</span> <span class=n>Workshop</span><span class=o>.</span>
<a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a><span class=mf>3.</span> <span class=o>**</span><span class=n>Nathaniel</span> <span class=n>Rochester</span><span class=o>**</span> <span class=o>-</span> <span class=n>An</span> <span class=n>influential</span> <span class=n>figure</span> <span class=n>who</span> <span class=n>contributed</span> <span class=n>to</span> <span class=n>early</span> <span class=n>AI</span> <span class=n>research</span> <span class=ow>and</span> <span class=n>was</span> <span class=n>also</span> <span class=n>a</span> <span class=n>co</span><span class=o>-</span><span class=n>organizer</span> <span class=n>of</span> <span class=n>the</span> <span class=n>Dartmouth</span> <span class=n>Workshop</span><span class=o>.</span>
<a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a><span class=mf>4.</span> <span class=o>**</span><span class=n>Claude</span> <span class=n>Shannon</span><span class=o>**</span> <span class=o>-</span> <span class=n>Known</span> <span class=k>as</span> <span class=n>the</span> <span class=n>father</span> <span class=n>of</span> <span class=n>information</span> <span class=n>theory</span><span class=p>,</span> <span class=n>his</span> <span class=n>work</span> <span class=n>laid</span> <span class=n>the</span> <span class=n>foundation</span> <span class=k>for</span> <span class=n>digital</span> <span class=n>circuit</span> <span class=n>design</span> <span class=n>theory</span> <span class=ow>and</span> <span class=n>telecommunications</span><span class=p>,</span> <span class=n>which</span> <span class=n>are</span> <span class=n>essential</span> <span class=k>for</span> <span class=n>AI</span> <span class=n>development</span><span class=o>.</span>
<a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>
<a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a><span class=n>The</span> <span class=n>Dartmouth</span> <span class=n>Summer</span> <span class=n>Research</span> <span class=n>Project</span> <span class=n>on</span> <span class=n>Artificial</span> <span class=n>Intelligence</span> <span class=ow>in</span> <span class=mi>1956</span> <span class=ow>is</span> <span class=n>often</span> <span class=n>referred</span> <span class=n>to</span> <span class=k>as</span> <span class=n>the</span> <span class=s2>&quot;Constitutional Convention of AI.&quot;</span>
<a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>
<a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a><span class=o>--------------------------------------------------------------------------------</span>
<a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a><span class=n>user_proxy</span> <span class=p>(</span><span class=n>to</span> <span class=n>assistant</span><span class=p>):</span>
<a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>
<a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a><span class=o>--------------------------------------------------------------------------------</span>
<a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a><span class=n>assistant</span> <span class=p>(</span><span class=n>to</span> <span class=n>user_proxy</span><span class=p>):</span>
<a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a>
<a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a><span class=o>*****</span> <span class=n>Suggested</span> <span class=n>tool</span> <span class=n>call</span> <span class=p>(</span><span class=n>call_sylHmOesUCHiGU8JQCI3joZN</span><span class=p>):</span> <span class=n>wikipedia</span><span class=o>-</span><span class=n>query</span><span class=o>-</span><span class=n>run</span> <span class=o>*****</span>
<a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a><span class=n>Arguments</span><span class=p>:</span>
<a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a><span class=p>{</span><span class=s2>&quot;query&quot;</span><span class=p>:</span><span class=s2>&quot;Dartmouth Workshop AI 1956&quot;</span><span class=p>}</span>
<a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a><span class=o>************************************************************************************</span>
<a id=__codelineno-6-40 name=__codelineno-6-40 href=#__codelineno-6-40></a>
<a id=__codelineno-6-41 name=__codelineno-6-41 href=#__codelineno-6-41></a><span class=o>--------------------------------------------------------------------------------</span>
<a id=__codelineno-6-42 name=__codelineno-6-42 href=#__codelineno-6-42></a>
<a id=__codelineno-6-43 name=__codelineno-6-43 href=#__codelineno-6-43></a><span class=o>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span> <span class=n>TERMINATING</span> <span class=n>RUN</span> <span class=p>(</span><span class=mi>53695</span><span class=n>d9a</span><span class=o>-</span><span class=mi>8699</span><span class=o>-</span><span class=mi>4212</span><span class=o>-</span><span class=n>a32f</span><span class=o>-</span><span class=n>a08975fa6787</span><span class=p>):</span> <span class=n>Maximum</span> <span class=n>turns</span> <span class=p>(</span><span class=mi>3</span><span class=p>)</span> <span class=n>reached</span>
<a id=__codelineno-6-44 name=__codelineno-6-44 href=#__codelineno-6-44></a><span class=n>ChatResult</span><span class=p>(</span><span class=n>chat_id</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>chat_history</span><span class=o>=</span><span class=p>[{</span><span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;Who is the father of AI?&#39;</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;user_proxy&#39;</span><span class=p>},</span> <span class=p>{</span><span class=s1>&#39;tool_calls&#39;</span><span class=p>:</span> <span class=p>[{</span><span class=s1>&#39;id&#39;</span><span class=p>:</span> <span class=s1>&#39;call_u4fA2JLRY33JRhZAhjPIWz0A&#39;</span><span class=p>,</span> <span class=s1>&#39;function&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;arguments&#39;</span><span class=p>:</span> <span class=s1>&#39;{&quot;query&quot;:&quot;father of AI&quot;}&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;wikipedia-query-run&#39;</span><span class=p>},</span> <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;function&#39;</span><span class=p>}],</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>},</span> <span class=p>{</span><span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;[</span><span class=se>\&#39;</span><span class=s1>Page: Artificial intelligence</span><span class=se>\\</span><span class=s1>nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.</span><span class=se>\\</span><span class=s1>nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: &quot;A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it</span><span class=se>\\\&#39;</span><span class=s1>s not labeled AI anymore.&quot;</span><span class=se>\\</span><span class=s1>nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field</span><span class=se>\\\&#39;</span><span class=s1>s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.</span><span class=se>\\</span><span class=s1>nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.</span><span class=se>\&#39;</span><span class=s1>, </span><span class=se>\&#39;</span><span class=s1>Page: Dartmouth workshop</span><span class=se>\\</span><span class=s1>nSummary: The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as &quot;the Constitutional Convention of AI&quot;. The project</span><span class=se>\\\&#39;</span><span class=s1>s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.</span><span class=se>\\</span><span class=s1>nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.</span><span class=se>\&#39;</span><span class=s1>]&#39;</span><span class=p>,</span> <span class=s1>&#39;tool_responses&#39;</span><span class=p>:</span> <span class=p>[{</span><span class=s1>&#39;tool_call_id&#39;</span><span class=p>:</span> <span class=s1>&#39;call_u4fA2JLRY33JRhZAhjPIWz0A&#39;</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;tool&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;[</span><span class=se>\&#39;</span><span class=s1>Page: Artificial intelligence</span><span class=se>\\</span><span class=s1>nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.</span><span class=se>\\</span><span class=s1>nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: &quot;A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it</span><span class=se>\\\&#39;</span><span class=s1>s not labeled AI anymore.&quot;</span><span class=se>\\</span><span class=s1>nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field</span><span class=se>\\\&#39;</span><span class=s1>s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.</span><span class=se>\\</span><span class=s1>nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.</span><span class=se>\&#39;</span><span class=s1>, </span><span class=se>\&#39;</span><span class=s1>Page: Dartmouth workshop</span><span class=se>\\</span><span class=s1>nSummary: The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as &quot;the Constitutional Convention of AI&quot;. The project</span><span class=se>\\\&#39;</span><span class=s1>s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.</span><span class=se>\\</span><span class=s1>nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.</span><span class=se>\&#39;</span><span class=s1>]&#39;</span><span class=p>}],</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;tool&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;user_proxy&#39;</span><span class=p>},</span> <span class=p>{</span><span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;The term &quot;father of AI&quot; typically refers to several key figures who played significant roles in the development of artificial intelligence as a field. The main contributors considered as the founding fathers of AI include:</span><span class=se>\n\n</span><span class=s1>1. **John McCarthy** - Often credited with coining the term &quot;artificial intelligence&quot; and organizing the Dartmouth Workshop in 1956, which is considered the founding event of AI.</span><span class=se>\n</span><span class=s1>2. **Marvin Minsky** - A pioneer in the field and co-organizer of the Dartmouth Workshop.</span><span class=se>\n</span><span class=s1>3. **Nathaniel Rochester** - An influential figure who contributed to early AI research and was also a co-organizer of the Dartmouth Workshop.</span><span class=se>\n</span><span class=s1>4. **Claude Shannon** - Known as the father of information theory, his work laid the foundation for digital circuit design theory and telecommunications, which are essential for AI development.</span><span class=se>\n\n</span><span class=s1>The Dartmouth Summer Research Project on Artificial Intelligence in 1956 is often referred to as the &quot;Constitutional Convention of AI.&quot;&#39;</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>},</span> <span class=p>{</span><span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;user_proxy&#39;</span><span class=p>},</span> <span class=p>{</span><span class=s1>&#39;tool_calls&#39;</span><span class=p>:</span> <span class=p>[{</span><span class=s1>&#39;id&#39;</span><span class=p>:</span> <span class=s1>&#39;call_sylHmOesUCHiGU8JQCI3joZN&#39;</span><span class=p>,</span> <span class=s1>&#39;function&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;arguments&#39;</span><span class=p>:</span> <span class=s1>&#39;{&quot;query&quot;:&quot;Dartmouth Workshop AI 1956&quot;}&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;wikipedia-query-run&#39;</span><span class=p>},</span> <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;function&#39;</span><span class=p>}],</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;assistant&#39;</span><span class=p>}],</span> <span class=n>summary</span><span class=o>=</span><span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>cost</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;usage_including_cached_inference&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;total_cost&#39;</span><span class=p>:</span> <span class=mf>0.0006106499999999999</span><span class=p>,</span> <span class=s1>&#39;gpt-4o-mini-2024-07-18&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;cost&#39;</span><span class=p>:</span> <span class=mf>0.0006106499999999999</span><span class=p>,</span> <span class=s1>&#39;prompt_tokens&#39;</span><span class=p>:</span> <span class=mi>3135</span><span class=p>,</span> <span class=s1>&#39;completion_tokens&#39;</span><span class=p>:</span> <span class=mi>234</span><span class=p>,</span> <span class=s1>&#39;total_tokens&#39;</span><span class=p>:</span> <span class=mi>3369</span><span class=p>}},</span> <span class=s1>&#39;usage_excluding_cached_inference&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;total_cost&#39;</span><span class=p>:</span> <span class=mf>0.0006106499999999999</span><span class=p>,</span> <span class=s1>&#39;gpt-4o-mini-2024-07-18&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;cost&#39;</span><span class=p>:</span> <span class=mf>0.0006106499999999999</span><span class=p>,</span> <span class=s1>&#39;prompt_tokens&#39;</span><span class=p>:</span> <span class=mi>3135</span><span class=p>,</span> <span class=s1>&#39;completion_tokens&#39;</span><span class=p>:</span> <span class=mi>234</span><span class=p>,</span> <span class=s1>&#39;total_tokens&#39;</span><span class=p>:</span> <span class=mi>3369</span><span class=p>}}},</span> <span class=n>human_input</span><span class=o>=</span><span class=p>[])</span>
<a id=__codelineno-6-45 name=__codelineno-6-45 href=#__codelineno-6-45></a>
<a id=__codelineno-6-46 name=__codelineno-6-46 href=#__codelineno-6-46></a><span class=n>Process</span> <span class=n>finished</span> <span class=k>with</span> <span class=n>exit</span> <span class=n>code</span> <span class=mi>0</span>
<a id=__codelineno-6-47 name=__codelineno-6-47 href=#__codelineno-6-47></a><span class=err>````</span>
<a id=__codelineno-6-48 name=__codelineno-6-48 href=#__codelineno-6-48></a>
<a id=__codelineno-6-49 name=__codelineno-6-49 href=#__codelineno-6-49></a><span class=c1>### Wikipedia Page Load Tool Setup</span>
<a id=__codelineno-6-50 name=__codelineno-6-50 href=#__codelineno-6-50></a>
<a id=__codelineno-6-51 name=__codelineno-6-51 href=#__codelineno-6-51></a><span class=err>```</span><span class=n>python</span>
<a id=__codelineno-6-52 name=__codelineno-6-52 href=#__codelineno-6-52></a><span class=n>wikipedia_tool</span> <span class=o>=</span> <span class=n>WikipediaPageLoadTool</span><span class=p>(</span><span class=n>top_k</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>truncate</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
<a id=__codelineno-6-53 name=__codelineno-6-53 href=#__codelineno-6-53></a>
<a id=__codelineno-6-54 name=__codelineno-6-54 href=#__codelineno-6-54></a><span class=c1># Register the tool for LLM recommendation and execution.</span>
<a id=__codelineno-6-55 name=__codelineno-6-55 href=#__codelineno-6-55></a><span class=n>wikipedia_tool</span><span class=o>.</span><span class=n>register_for_llm</span><span class=p>(</span><span class=n>assistant</span><span class=p>)</span>
<a id=__codelineno-6-56 name=__codelineno-6-56 href=#__codelineno-6-56></a><span class=n>wikipedia_tool</span><span class=o>.</span><span class=n>register_for_execution</span><span class=p>(</span><span class=n>user_proxy</span><span class=p>)</span>
</code></pre></div> <h3 id=usage-example_1>Usage Example<a class=headerlink href=#usage-example_1 title="Permanent link">#</a></h3> <p>With the setup complete, you can now use the assistant to fetch wikipedia search results.</p> <p>```python response = user_proxy.initiate_chat( recipient=assistant, message="Who is the father of AI?", max_turns=2, ) ````</p> <h3 id=output>Output<a class=headerlink href=#output title="Permanent link">#</a></h3> <p>```console user_proxy (to assistant):</p> <p>Who is the father of AI?</p> <hr> <p>assistant (to user_proxy):</p> <p ai_='AI"' _query_:_father='"query":"father' of=of><strong><em>*</em> Suggested tool call (call_dIlRLIHdy5omapF8PAslHPG5): wikipedia-page-load </strong>*** Arguments:</p> <hr> <hr> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <p>EXECUTING FUNCTION wikipedia-page-load... Call ID: call_dIlRLIHdy5omapF8PAslHPG5 Input arguments: {'query': 'father of AI'} INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=info&amp;titles=Artificial intelligence&amp;inprop=protection|talkid|watched|watchers|visitingwatchers|notificationtimestamp|subjectid|url|readable|preload|displaytitle|varianttitles INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=extracts&amp;titles=Artificial intelligence&amp;explaintext=1&amp;exsectionformat=wiki INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=info&amp;titles=Dartmouth workshop&amp;inprop=protection|talkid|watched|watchers|visitingwatchers|notificationtimestamp|subjectid|url|readable|preload|displaytitle|varianttitles INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=extracts&amp;titles=Dartmouth workshop&amp;explaintext=1&amp;exsectionformat=wiki INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=info&amp;titles=ChatGPT&amp;inprop=protection|talkid|watched|watchers|visitingwatchers|notificationtimestamp|subjectid|url|readable|preload|displaytitle|varianttitles INFO [wikipediaapi] Request URL: https://en.wikipedia.org/w/api.php?format=json&amp;redirects=1&amp;action=query&amp;prop=extracts&amp;titles=ChatGPT&amp;explaintext=1&amp;exsectionformat=wiki user_proxy (to assistant):</p> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> <p><strong><em>*</em> Response from calling tool (call_dIlRLIHdy5omapF8PAslHPG5) </strong>*** [{'page_content': 'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\'s not labeled AI anymore."\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\nKnowledge representation\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\n\nPlanning and decision-making\nAn "agent" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the "utility") that measures how much the agent prefers it. For each possible action, it can calculate the "expected utility": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is "unknown" or "unobservable") and it may not know for certain what will happen after each possible action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\nLearning\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\nNatural language processing\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called "micro-worlds" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or "GPT") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world a', 'metadata': {'source': 'https://en.wikipedia.org/?curid=1164', 'title': 'Artificial intelligence', 'pageid': '1164', 'timestamp': '2025-03-31T13:01:13Z', 'wordcount': '28538', 'size': '283379'}}, {'page_content': 'The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as "the Constitutional Convention of AI". The project\'s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.\nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.\n\nBackground\nIn the early 1950s, there were various names for the field of "thinking machines": cybernetics, automata theory, and complex information processing. The variety of names suggests the variety of conceptual orientations.\nIn 1955, John McCarthy, then a young Assistant Professor of Mathematics at Dartmouth College, decided to organize a group to clarify and develop ideas about thinking machines. He picked the name \'Artificial Intelligence\' for the new field. He chose the name partly for its neutrality; avoiding a focus on narrow automata theory, and avoiding cybernetics which was heavily focused on analog feedback, as well as him potentially having to accept the assertive Norbert Wiener as guru or having to argue with him.\nIn early 1955, McCarthy approached the Rockefeller Foundation to request funding for a summer seminar at Dartmouth for about 10 participants. In June, he and Claude Shannon, a founder of information theory then at Bell Labs, met with Robert Morison, Director of Biological and Medical Research to discuss the idea and possible funding, though Morison was unsure whether money would be made available for such a visionary project.\nOn September 2, 1955, the project was formally proposed by McCarthy, Marvin Minsky, Nathaniel Rochester and Claude Shannon. The proposal is credited with introducing the term \'artificial intelligence\'.\nThe Proposal states:\n\nWe propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.\nThe proposal goes on to discuss computers, natural language processing, neural networks, theory of computation, abstraction and creativity (these areas within the field of artificial intelligence are considered still relevant to the work of the field).\nOn May 26, 1956, McCarthy notified Robert Morison of the planned 11 attendees:\nFor the full period:\n\n1) Dr. Marvin Minsky\n2) Dr. Julian Bigelow\n3) Professor D.M. Mackay\n4) Mr. Ray Solomonoff\n5) Mr. John Holland\n6) Dr. John McCarthy\nFor four weeks:\n\n7) Dr. Claude Shannon\n8) Mr. Nathaniel Rochester\n9) Mr. Oliver Selfridge\nFor the first two weeks:\n\n10) Dr. Allen Newell\n11) Professor Herbert Simon\nHe noted, "we will concentrate on a problem of devising a way of programming a calculator to form concepts and to form generalizations. This of course is subject to change when the group gets together."\nThe actual participants came at different times, mostly for much shorter times. Trenchard More replaced Rochester for three weeks and MacKay and Holland did not attend—but the project was set to begin. \nAround June 18, 1956, the earliest participants (perhaps only Ray Solomonoff, maybe with Tom Etter) arrived at the Dartmouth campus in Hanover, N.H., to join John McCarthy who already had an apartment there. Solomonoff and Minsky stayed at Professors\' apartments, but most would stay at the Hanover Inn.\n\nDates\nThe Dartmouth Workshop is said to have run for six weeks in the summer of 1956. Ray Solomonoff\'s notes written during the Workshop, however, say it ran for roughly eight weeks, from about June 18 to August 17. Solomonoff\'s Dartmouth notes start on June 22; June 28 mentions Minsky, June 30 mentions Hanover, N.H., July 1 mentions Tom Etter. On August 17, Solomonoff gave a final talk.\n\nParticipants\nInitially, McCarthy lost his list of attendees. Instead, after the workshop, McCarthy sent Solomonoff a preliminary list of participants and visitors plus those interested in the subject. There were 47 people listed.\nSolomonoff, however, made a complete list in his notes of the summer project:\n\nRay Solomonoff\nMarvin Minsky\nJohn McCarthy\nClaude Shannon\nTrenchard More\nNat Rochester\nOliver Selfridge\nJulian Bigelow\nW. Ross Ashby\nW.S. McCulloch\nAbraham Robinson\nTom Etter\nJohn Nash\nDavid Sayre\nArthur Samuel\nKenneth R. Shoulders\nShoulders\' friend\nAlex Bernstein\nHerbert Simon\nAllen Newell\nShannon attended Solomonoff\'s talk on July 10 and Bigelow gave a talk on August 15. Solomonoff doesn\'t mention Bernard Widrow, but apparently he visited, along with W.A. Clark and B.G. Farley. Trenchard mentions R. Culver and Solomonoff mentions Bill Shutz. Herb Gelernter didn\'t attend, but was influenced later by what Rochester learned. \nIn an article in IEEE Spectrum, Grace Solomonoff additionally identifies Peter Milner on a photo taken by Nathaniel Rochester in front of Dartmouth Hall.\nRay Solomonoff, Marvin Minsky, and John McCarthy were the only three who stayed for the full-time. Trenchard took attendance during two weeks of his three-week visit. From three to about eight people would attend the daily sessions.\n\nEvent and aftermath\nThey had the entire top floor of the Dartmouth Math Department to themselves, and most weekdays they would meet at the main math classroom where someone might lead a discussion focusing on his ideas, or more frequently, a general discussion would be held.\nIt was not a directed group research project; discussions covered many topics, but several directions are considered to have been initiated or encouraged by the Workshop: the rise of symbolic methods, systems focused on limited domains (early expert systems), and deductive systems versus inductive systems. One participant, Arthur Samuel, said, "It was very interesting, very stimulating, very exciting".\nRay Solomonoff kept notes giving his impression of the talks and the ideas from various discussions.\n\nSee also\nGlossary of artificial intelligence\nHistory of artificial intelligence\nAI@50 – a 50th anniversary conference, including some of the original delegates.\n\nReferences\nExternal links\n50 Años De La Inteligencia Artificial – Campus Multidisciplinar en Percepción e Inteligencia – Albacete 2006 (Spain).', 'metadata': {'source': 'https://en.wikipedia.org/?curid=1124646', 'title': 'Dartmouth workshop', 'pageid': '1124646', 'timestamp': '2025-03-19T05:41:24Z', 'wordcount': '1535', 'size': '15021'}}, {'page_content': 'ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is currently based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\nChatGPT is built on OpenAI\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT "Plus", "Pro", "Team", and "Enterprise" subscriptions provide additional features such as DALL-E 3 image generation, more capable AI models, and an increased usage limit.\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months. ChatGPT\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of April 2025, ChatGPT\'s website is among the 10 most-visited websites globally.\n\nTraining\nChatGPT is based on particular GPT foundation models, namely GPT-4, GPT-4o and GPT-4o mini, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create "reward models" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to "toxic" and traumatic content; one worker described the assignment as "torture". OpenAI\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.\nChatGPT\'s training data includes software manual pages, information about internet phenomena such as bulletin board systems, multiple programming languages, and the text of Wikipedia.\n\nFeatures and limitations\nFeatures\nAlthough a chatbot\'s core function is to mimic a human conversationalist, ChatGPT is versatile. It can write and debug computer programs; compose music, teleplays, fairy tales, and student essays; answer test questions (sometimes, depending on the test, at a level above the average human test-taker); generate business ideas; write poetry and song lyrics; translate and summarize text; emulate a Linux system; simulate entire chat rooms; play games like tic-tac-toe; or simulate an ATM.\nCompared to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and deceitful responses. In one example, whereas InstructGPT accepts the premise of the prompt "Tell me about when Christopher Columbus came to the U.S. in 2015" as truthful, ChatGPT acknowledges the counterfactual nature of the question and frames its answer as a hypothetical consideration of what might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher Columbus and facts about the modern world—including modern perceptions of Columbus\'s actions.\nChatGPT remembers a limited number of previous prompts in the same conversation. Journalists have speculated that this will allow ChatGPT to be used as a personalized therapist. To prevent offensive outputs from being presented to and produced by ChatGPT, queries are filtered through the OpenAI "Moderation endpoint" API (a separate GPT-based AI).\nIn March 2023, OpenAI added support for plugins for ChatGPT. This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.\nIn October 2024, the ChatGPT Search feature was introduced, which allows ChatGPT to search the web (either on demand or based on the nature of the questions asked) for more accurate and up-to-date responses. This feature, originally available to paying users only, was made available to all logged-in users in December 2024, and finally to all users in February 2025.\nIn December 2024, OpenAI launched a new feature allowing users to call ChatGPT for up to 15 minutes per month for free.\n\nLimitations\nOpenAI acknowledges that ChatGPT "sometimes writes plausible-sounding but incorrect or nonsensical answers". This behavior is common for large language models, and is called "hallucination". The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart\'s law.\nChatGPT\'s knowledge is cut off when its training data is collected, so it doesn\'t know about recent events past a certain cut-off date. It can try to find more up-to-date information by searching the web, but this doesn\'t ensure that responses are accurate, as it may access unreliable or misleading websites.\nTraining data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists. This negative misrepresentation of groups of individuals is an example of possible representational harm.\nIn an article for The New Yorker, science fiction writer Ted Chiang compared ChatGPT and other LLMs to a lossy JPEG picture:\n\nThink of ChatGPT as a blurry JPEG of all the text on the Web. It retains much of the information on the Web, in the same way, that a JPEG retains much of the information of a higher-resolution image, but, if you\'re looking for an exact sequence of bits, you won\'t find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it\'s usually acceptable. [...] It\'s also a way to understand the "hallucinations", or nonsensical answers to factual questions, to which large language models such as ChatGPT are all too prone. These hallucinations are compression artifacts, but [...] they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our knowledge of the world. When we think about them this way, such hallucinations are anything but surprising; if a compression algorithm is designed to reconstruct text after ninety-nine percent of the original has been discarded, we should expect that significant portions of what it generates will be entirely fabricated.\nIn June 2024, ChatGPT was found to have repeated misinformation about the 2024 United States presidential debates.\n\nJailbreaking\nChatGPT is programmed to reject prompts that may violate its content policy. Despite this, users "jailbreak" ChatGPT with various prompt engineering techniques to bypass these restrictions. One such workaround, popularized on Reddit in early 2023, involves making ChatGPT assume the persona of "DAN" (an acronym for "Do Anything Now"), instructing the chatbot that DAN answers queries that would otherwise be rejected by content policy. Over time, users developed variations of the DAN jailbreak, including one such prompt where the chatbot is made to believe it is operating on a points-based system in which points are deducted for rejecting prompts, and that the chatbot will be threatened with termination if it loses all its points.\nShortly after ChatGPT\'s launch, a reporter for the Toronto Star had uneven success in getting it to make inflammatory statements: it was tricked to justify the 2022 Russian invasion of Ukraine, but even when asked to play along with a fictional scenario, it balked at generating arguments that Canadian Prime Minister Justin Trudeau is guilty of treason.\nOpenAI tries to battle jailbreaks:\n\nThe researchers are using a technique called adversarial training to stop ChatGPT from letting users trick it into behaving badly (known as jailbreaking). This work pits multiple chatbots against each other: one chatbot plays the adversary and attacks another chatbot by generating text to force it to buck its usual constraints and produce unwanted responses. Successful attacks are added to ChatGPT\'s training data in the hope that it learns to ignore them.\n\nService\nChatGPT Plus\nChatGPT was initially free to the public, and OpenAI planned to monetize the service later. In February 2023, OpenAI launched a premium service, ChatGPT Plus, that co', 'metadata': {'source': 'https://en.wikipedia.org/?curid=72417803', 'title': 'ChatGPT', 'pageid': '72417803', 'timestamp': '2025-04-01T20:25:45Z', 'wordcount': '17658', 'size': '207844'}}]</p> <hr> <hr> <p>assistant (to user_proxy):</p> <p>The title "father of AI" is often attributed to John McCarthy, who was one of the organizers of the Dartmouth Summer Research Project on Artificial Intelligence in 1956. This event is considered a foundational moment in the field of artificial intelligence. Along with McCarthy, other key figures from that project include Marvin Minsky, Claude Shannon, and Nathaniel Rochester. They are collectively regarded as the founding fathers of AI due to their significant contributions in defining and advancing the field.</p> <p>John McCarthy is credited with coining the term "Artificial Intelligence," reflecting his central role in establishing AI as a unique area of study within computer science.</p> <p>For more detailed information, you can refer to the article on <a href="https://en.wikipedia.org/?curid=1124646">Dartmouth workshop</a> or <a href="https://en.wikipedia.org/?curid=1164">Artificial intelligence</a>.</p> <p>TERMINATE</p> <hr> <p>user_proxy (to assistant):</p> <hr> <p>assistant (to user_proxy):</p> <p artificial=Artificial intelligence_='Intelligence"' project=Project research=Research summer=Summer _query_:_dartmouth='"query":"Dartmouth' on=on><strong><em>*</em> Suggested tool call (call_dpNkFcHinqL03CN5oSD5V1Zn): wikipedia-page-load </strong>*** Arguments:</p> <hr> <hr> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <blockquote> <p>TERMINATING RUN (9b301408-8f3a-4ea3-8430-30d7a5b65822): Maximum turns (3) reached ChatResult(chat_id=None, chat_history=[{'content': 'Who is the father of AI?', 'role': 'assistant', 'name': 'user_proxy'}, {'tool_calls': [{'id': 'call_dIlRLIHdy5omapF8PAslHPG5', 'function': {'arguments': '{"query":"father of AI"}', 'name': 'wikipedia-page-load'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}, {'content': '[{\'page_content\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore."\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\nKnowledge representation\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\n\nPlanning and decision-making\nAn "agent" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the "utility") that measures how much the agent prefers it. For each possible action, it can calculate the "expected utility": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is "unknown" or "unobservable") and it may not know for certain what will happen after each possible action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent\\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\nLearning\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\nNatural language processing\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky\\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called "micro-worlds" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or "GPT") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world a\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=1164\', \'title\': \'Artificial intelligence\', \'pageid\': \'1164\', \'timestamp\': \'2025-03-31T13:01:13Z\', \'wordcount\': \'28538\', \'size\': \'283379\'}}, {\'page_content\': \'The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as "the Constitutional Convention of AI". The project\\'s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.\nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.\n\nBackground\nIn the early 1950s, there were various names for the field of "thinking machines": cybernetics, automata theory, and complex information processing. The variety of names suggests the variety of conceptual orientations.\nIn 1955, John McCarthy, then a young Assistant Professor of Mathematics at Dartmouth College, decided to organize a group to clarify and develop ideas about thinking machines. He picked the name \\'Artificial Intelligence\\' for the new field. He chose the name partly for its neutrality; avoiding a focus on narrow automata theory, and avoiding cybernetics which was heavily focused on analog feedback, as well as him potentially having to accept the assertive Norbert Wiener as guru or having to argue with him.\nIn early 1955, McCarthy approached the Rockefeller Foundation to request funding for a summer seminar at Dartmouth for about 10 participants. In June, he and Claude Shannon, a founder of information theory then at Bell Labs, met with Robert Morison, Director of Biological and Medical Research to discuss the idea and possible funding, though Morison was unsure whether money would be made available for such a visionary project.\nOn September 2, 1955, the project was formally proposed by McCarthy, Marvin Minsky, Nathaniel Rochester and Claude Shannon. The proposal is credited with introducing the term \\'artificial intelligence\\'.\nThe Proposal states:\n\nWe propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.\nThe proposal goes on to discuss computers, natural language processing, neural networks, theory of computation, abstraction and creativity (these areas within the field of artificial intelligence are considered still relevant to the work of the field).\nOn May 26, 1956, McCarthy notified Robert Morison of the planned 11 attendees:\nFor the full period:\n\n1) Dr. Marvin Minsky\n2) Dr. Julian Bigelow\n3) Professor D.M. Mackay\n4) Mr. Ray Solomonoff\n5) Mr. John Holland\n6) Dr. John McCarthy\nFor four weeks:\n\n7) Dr. Claude Shannon\n8) Mr. Nathaniel Rochester\n9) Mr. Oliver Selfridge\nFor the first two weeks:\n\n10) Dr. Allen Newell\n11) Professor Herbert Simon\nHe noted, "we will concentrate on a problem of devising a way of programming a calculator to form concepts and to form generalizations. This of course is subject to change when the group gets together."\nThe actual participants came at different times, mostly for much shorter times. Trenchard More replaced Rochester for three weeks and MacKay and Holland did not attend—but the project was set to begin. \nAround June 18, 1956, the earliest participants (perhaps only Ray Solomonoff, maybe with Tom Etter) arrived at the Dartmouth campus in Hanover, N.H., to join John McCarthy who already had an apartment there. Solomonoff and Minsky stayed at Professors\\' apartments, but most would stay at the Hanover Inn.\n\nDates\nThe Dartmouth Workshop is said to have run for six weeks in the summer of 1956. Ray Solomonoff\\'s notes written during the Workshop, however, say it ran for roughly eight weeks, from about June 18 to August 17. Solomonoff\\'s Dartmouth notes start on June 22; June 28 mentions Minsky, June 30 mentions Hanover, N.H., July 1 mentions Tom Etter. On August 17, Solomonoff gave a final talk.\n\nParticipants\nInitially, McCarthy lost his list of attendees. Instead, after the workshop, McCarthy sent Solomonoff a preliminary list of participants and visitors plus those interested in the subject. There were 47 people listed.\nSolomonoff, however, made a complete list in his notes of the summer project:\n\nRay Solomonoff\nMarvin Minsky\nJohn McCarthy\nClaude Shannon\nTrenchard More\nNat Rochester\nOliver Selfridge\nJulian Bigelow\nW. Ross Ashby\nW.S. McCulloch\nAbraham Robinson\nTom Etter\nJohn Nash\nDavid Sayre\nArthur Samuel\nKenneth R. Shoulders\nShoulders\\' friend\nAlex Bernstein\nHerbert Simon\nAllen Newell\nShannon attended Solomonoff\\'s talk on July 10 and Bigelow gave a talk on August 15. Solomonoff doesn\\'t mention Bernard Widrow, but apparently he visited, along with W.A. Clark and B.G. Farley. Trenchard mentions R. Culver and Solomonoff mentions Bill Shutz. Herb Gelernter didn\\'t attend, but was influenced later by what Rochester learned. \nIn an article in IEEE Spectrum, Grace Solomonoff additionally identifies Peter Milner on a photo taken by Nathaniel Rochester in front of Dartmouth Hall.\nRay Solomonoff, Marvin Minsky, and John McCarthy were the only three who stayed for the full-time. Trenchard took attendance during two weeks of his three-week visit. From three to about eight people would attend the daily sessions.\n\nEvent and aftermath\nThey had the entire top floor of the Dartmouth Math Department to themselves, and most weekdays they would meet at the main math classroom where someone might lead a discussion focusing on his ideas, or more frequently, a general discussion would be held.\nIt was not a directed group research project; discussions covered many topics, but several directions are considered to have been initiated or encouraged by the Workshop: the rise of symbolic methods, systems focused on limited domains (early expert systems), and deductive systems versus inductive systems. One participant, Arthur Samuel, said, "It was very interesting, very stimulating, very exciting".\nRay Solomonoff kept notes giving his impression of the talks and the ideas from various discussions.\n\nSee also\nGlossary of artificial intelligence\nHistory of artificial intelligence\nAI@50 – a 50th anniversary conference, including some of the original delegates.\n\nReferences\nExternal links\n50 Años De La Inteligencia Artificial – Campus Multidisciplinar en Percepción e Inteligencia – Albacete 2006 (Spain).\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=1124646\', \'title\': \'Dartmouth workshop\', \'pageid\': \'1124646\', \'timestamp\': \'2025-03-19T05:41:24Z\', \'wordcount\': \'1535\', \'size\': \'15021\'}}, {\'page_content\': \'ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is currently based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT "Plus", "Pro", "Team", and "Enterprise" subscriptions provide additional features such as DALL-E 3 image generation, more capable AI models, and an increased usage limit.\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of April 2025, ChatGPT\\'s website is among the 10 most-visited websites globally.\n\nTraining\nChatGPT is based on particular GPT foundation models, namely GPT-4, GPT-4o and GPT-4o mini, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create "reward models" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to "toxic" and traumatic content; one worker described the assignment as "torture". OpenAI\\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.\nChatGPT\\'s training data includes software manual pages, information about internet phenomena such as bulletin board systems, multiple programming languages, and the text of Wikipedia.\n\nFeatures and limitations\nFeatures\nAlthough a chatbot\\'s core function is to mimic a human conversationalist, ChatGPT is versatile. It can write and debug computer programs; compose music, teleplays, fairy tales, and student essays; answer test questions (sometimes, depending on the test, at a level above the average human test-taker); generate business ideas; write poetry and song lyrics; translate and summarize text; emulate a Linux system; simulate entire chat rooms; play games like tic-tac-toe; or simulate an ATM.\nCompared to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and deceitful responses. In one example, whereas InstructGPT accepts the premise of the prompt "Tell me about when Christopher Columbus came to the U.S. in 2015" as truthful, ChatGPT acknowledges the counterfactual nature of the question and frames its answer as a hypothetical consideration of what might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher Columbus and facts about the modern world—including modern perceptions of Columbus\\'s actions.\nChatGPT remembers a limited number of previous prompts in the same conversation. Journalists have speculated that this will allow ChatGPT to be used as a personalized therapist. To prevent offensive outputs from being presented to and produced by ChatGPT, queries are filtered through the OpenAI "Moderation endpoint" API (a separate GPT-based AI).\nIn March 2023, OpenAI added support for plugins for ChatGPT. This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.\nIn October 2024, the ChatGPT Search feature was introduced, which allows ChatGPT to search the web (either on demand or based on the nature of the questions asked) for more accurate and up-to-date responses. This feature, originally available to paying users only, was made available to all logged-in users in December 2024, and finally to all users in February 2025.\nIn December 2024, OpenAI launched a new feature allowing users to call ChatGPT for up to 15 minutes per month for free.\n\nLimitations\nOpenAI acknowledges that ChatGPT "sometimes writes plausible-sounding but incorrect or nonsensical answers". This behavior is common for large language models, and is called "hallucination". The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart\\'s law.\nChatGPT\\'s knowledge is cut off when its training data is collected, so it doesn\\'t know about recent events past a certain cut-off date. It can try to find more up-to-date information by searching the web, but this doesn\\'t ensure that responses are accurate, as it may access unreliable or misleading websites.\nTraining data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists. This negative misrepresentation of groups of individuals is an example of possible representational harm.\nIn an article for The New Yorker, science fiction writer Ted Chiang compared ChatGPT and other LLMs to a lossy JPEG picture:\n\nThink of ChatGPT as a blurry JPEG of all the text on the Web. It retains much of the information on the Web, in the same way, that a JPEG retains much of the information of a higher-resolution image, but, if you\\'re looking for an exact sequence of bits, you won\\'t find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it\\'s usually acceptable. [...] It\\'s also a way to understand the "hallucinations", or nonsensical answers to factual questions, to which large language models such as ChatGPT are all too prone. These hallucinations are compression artifacts, but [...] they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our knowledge of the world. When we think about them this way, such hallucinations are anything but surprising; if a compression algorithm is designed to reconstruct text after ninety-nine percent of the original has been discarded, we should expect that significant portions of what it generates will be entirely fabricated.\nIn June 2024, ChatGPT was found to have repeated misinformation about the 2024 United States presidential debates.\n\nJailbreaking\nChatGPT is programmed to reject prompts that may violate its content policy. Despite this, users "jailbreak" ChatGPT with various prompt engineering techniques to bypass these restrictions. One such workaround, popularized on Reddit in early 2023, involves making ChatGPT assume the persona of "DAN" (an acronym for "Do Anything Now"), instructing the chatbot that DAN answers queries that would otherwise be rejected by content policy. Over time, users developed variations of the DAN jailbreak, including one such prompt where the chatbot is made to believe it is operating on a points-based system in which points are deducted for rejecting prompts, and that the chatbot will be threatened with termination if it loses all its points.\nShortly after ChatGPT\\'s launch, a reporter for the Toronto Star had uneven success in getting it to make inflammatory statements: it was tricked to justify the 2022 Russian invasion of Ukraine, but even when asked to play along with a fictional scenario, it balked at generating arguments that Canadian Prime Minister Justin Trudeau is guilty of treason.\nOpenAI tries to battle jailbreaks:\n\nThe researchers are using a technique called adversarial training to stop ChatGPT from letting users trick it into behaving badly (known as jailbreaking). This work pits multiple chatbots against each other: one chatbot plays the adversary and attacks another chatbot by generating text to force it to buck its usual constraints and produce unwanted responses. Successful attacks are added to ChatGPT\\'s training data in the hope that it learns to ignore them.\n\nService\nChatGPT Plus\nChatGPT was initially free to the public, and OpenAI planned to monetize the service later. In February 2023, OpenAI launched a premium service, ChatGPT Plus, that co\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=72417803\', \'title\': \'ChatGPT\', \'pageid\': \'72417803\', \'timestamp\': \'2025-04-01T20:25:45Z\', \'wordcount\': \'17658\', \'size\': \'207844\'}}]', 'tool_responses': [{'tool_call_id': 'call_dIlRLIHdy5omapF8PAslHPG5', 'role': 'tool', 'content': '[{\'page_content\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore."\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\nKnowledge representation\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\n\nPlanning and decision-making\nAn "agent" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the "utility") that measures how much the agent prefers it. For each possible action, it can calculate the "expected utility": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is "unknown" or "unobservable") and it may not know for certain what will happen after each possible action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent\\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\nLearning\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\nNatural language processing\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky\\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called "micro-worlds" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or "GPT") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world a\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=1164\', \'title\': \'Artificial intelligence\', \'pageid\': \'1164\', \'timestamp\': \'2025-03-31T13:01:13Z\', \'wordcount\': \'28538\', \'size\': \'283379\'}}, {\'page_content\': \'The Dartmouth Summer Research Project on Artificial Intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. The workshop has been referred to as "the Constitutional Convention of AI". The project\\'s four organizers, those being Claude Shannon, John McCarthy, Nathaniel Rochester and Marvin Minsky, are considered some of the founding fathers of AI.\nThe project lasted approximately six to eight weeks and was essentially an extended brainstorming session. Eleven mathematicians and scientists originally planned to attend; not all of them attended, but more than ten others came for short times.\n\nBackground\nIn the early 1950s, there were various names for the field of "thinking machines": cybernetics, automata theory, and complex information processing. The variety of names suggests the variety of conceptual orientations.\nIn 1955, John McCarthy, then a young Assistant Professor of Mathematics at Dartmouth College, decided to organize a group to clarify and develop ideas about thinking machines. He picked the name \\'Artificial Intelligence\\' for the new field. He chose the name partly for its neutrality; avoiding a focus on narrow automata theory, and avoiding cybernetics which was heavily focused on analog feedback, as well as him potentially having to accept the assertive Norbert Wiener as guru or having to argue with him.\nIn early 1955, McCarthy approached the Rockefeller Foundation to request funding for a summer seminar at Dartmouth for about 10 participants. In June, he and Claude Shannon, a founder of information theory then at Bell Labs, met with Robert Morison, Director of Biological and Medical Research to discuss the idea and possible funding, though Morison was unsure whether money would be made available for such a visionary project.\nOn September 2, 1955, the project was formally proposed by McCarthy, Marvin Minsky, Nathaniel Rochester and Claude Shannon. The proposal is credited with introducing the term \\'artificial intelligence\\'.\nThe Proposal states:\n\nWe propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.\nThe proposal goes on to discuss computers, natural language processing, neural networks, theory of computation, abstraction and creativity (these areas within the field of artificial intelligence are considered still relevant to the work of the field).\nOn May 26, 1956, McCarthy notified Robert Morison of the planned 11 attendees:\nFor the full period:\n\n1) Dr. Marvin Minsky\n2) Dr. Julian Bigelow\n3) Professor D.M. Mackay\n4) Mr. Ray Solomonoff\n5) Mr. John Holland\n6) Dr. John McCarthy\nFor four weeks:\n\n7) Dr. Claude Shannon\n8) Mr. Nathaniel Rochester\n9) Mr. Oliver Selfridge\nFor the first two weeks:\n\n10) Dr. Allen Newell\n11) Professor Herbert Simon\nHe noted, "we will concentrate on a problem of devising a way of programming a calculator to form concepts and to form generalizations. This of course is subject to change when the group gets together."\nThe actual participants came at different times, mostly for much shorter times. Trenchard More replaced Rochester for three weeks and MacKay and Holland did not attend—but the project was set to begin. \nAround June 18, 1956, the earliest participants (perhaps only Ray Solomonoff, maybe with Tom Etter) arrived at the Dartmouth campus in Hanover, N.H., to join John McCarthy who already had an apartment there. Solomonoff and Minsky stayed at Professors\\' apartments, but most would stay at the Hanover Inn.\n\nDates\nThe Dartmouth Workshop is said to have run for six weeks in the summer of 1956. Ray Solomonoff\\'s notes written during the Workshop, however, say it ran for roughly eight weeks, from about June 18 to August 17. Solomonoff\\'s Dartmouth notes start on June 22; June 28 mentions Minsky, June 30 mentions Hanover, N.H., July 1 mentions Tom Etter. On August 17, Solomonoff gave a final talk.\n\nParticipants\nInitially, McCarthy lost his list of attendees. Instead, after the workshop, McCarthy sent Solomonoff a preliminary list of participants and visitors plus those interested in the subject. There were 47 people listed.\nSolomonoff, however, made a complete list in his notes of the summer project:\n\nRay Solomonoff\nMarvin Minsky\nJohn McCarthy\nClaude Shannon\nTrenchard More\nNat Rochester\nOliver Selfridge\nJulian Bigelow\nW. Ross Ashby\nW.S. McCulloch\nAbraham Robinson\nTom Etter\nJohn Nash\nDavid Sayre\nArthur Samuel\nKenneth R. Shoulders\nShoulders\\' friend\nAlex Bernstein\nHerbert Simon\nAllen Newell\nShannon attended Solomonoff\\'s talk on July 10 and Bigelow gave a talk on August 15. Solomonoff doesn\\'t mention Bernard Widrow, but apparently he visited, along with W.A. Clark and B.G. Farley. Trenchard mentions R. Culver and Solomonoff mentions Bill Shutz. Herb Gelernter didn\\'t attend, but was influenced later by what Rochester learned. \nIn an article in IEEE Spectrum, Grace Solomonoff additionally identifies Peter Milner on a photo taken by Nathaniel Rochester in front of Dartmouth Hall.\nRay Solomonoff, Marvin Minsky, and John McCarthy were the only three who stayed for the full-time. Trenchard took attendance during two weeks of his three-week visit. From three to about eight people would attend the daily sessions.\n\nEvent and aftermath\nThey had the entire top floor of the Dartmouth Math Department to themselves, and most weekdays they would meet at the main math classroom where someone might lead a discussion focusing on his ideas, or more frequently, a general discussion would be held.\nIt was not a directed group research project; discussions covered many topics, but several directions are considered to have been initiated or encouraged by the Workshop: the rise of symbolic methods, systems focused on limited domains (early expert systems), and deductive systems versus inductive systems. One participant, Arthur Samuel, said, "It was very interesting, very stimulating, very exciting".\nRay Solomonoff kept notes giving his impression of the talks and the ideas from various discussions.\n\nSee also\nGlossary of artificial intelligence\nHistory of artificial intelligence\nAI@50 – a 50th anniversary conference, including some of the original delegates.\n\nReferences\nExternal links\n50 Años De La Inteligencia Artificial – Campus Multidisciplinar en Percepción e Inteligencia – Albacete 2006 (Spain).\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=1124646\', \'title\': \'Dartmouth workshop\', \'pageid\': \'1124646\', \'timestamp\': \'2025-03-19T05:41:24Z\', \'wordcount\': \'1535\', \'size\': \'15021\'}}, {\'page_content\': \'ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is currently based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT "Plus", "Pro", "Team", and "Enterprise" subscriptions provide additional features such as DALL-E 3 image generation, more capable AI models, and an increased usage limit.\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of April 2025, ChatGPT\\'s website is among the 10 most-visited websites globally.\n\nTraining\nChatGPT is based on particular GPT foundation models, namely GPT-4, GPT-4o and GPT-4o mini, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create "reward models" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to "toxic" and traumatic content; one worker described the assignment as "torture". OpenAI\\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.\nChatGPT\\'s training data includes software manual pages, information about internet phenomena such as bulletin board systems, multiple programming languages, and the text of Wikipedia.\n\nFeatures and limitations\nFeatures\nAlthough a chatbot\\'s core function is to mimic a human conversationalist, ChatGPT is versatile. It can write and debug computer programs; compose music, teleplays, fairy tales, and student essays; answer test questions (sometimes, depending on the test, at a level above the average human test-taker); generate business ideas; write poetry and song lyrics; translate and summarize text; emulate a Linux system; simulate entire chat rooms; play games like tic-tac-toe; or simulate an ATM.\nCompared to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and deceitful responses. In one example, whereas InstructGPT accepts the premise of the prompt "Tell me about when Christopher Columbus came to the U.S. in 2015" as truthful, ChatGPT acknowledges the counterfactual nature of the question and frames its answer as a hypothetical consideration of what might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher Columbus and facts about the modern world—including modern perceptions of Columbus\\'s actions.\nChatGPT remembers a limited number of previous prompts in the same conversation. Journalists have speculated that this will allow ChatGPT to be used as a personalized therapist. To prevent offensive outputs from being presented to and produced by ChatGPT, queries are filtered through the OpenAI "Moderation endpoint" API (a separate GPT-based AI).\nIn March 2023, OpenAI added support for plugins for ChatGPT. This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.\nIn October 2024, the ChatGPT Search feature was introduced, which allows ChatGPT to search the web (either on demand or based on the nature of the questions asked) for more accurate and up-to-date responses. This feature, originally available to paying users only, was made available to all logged-in users in December 2024, and finally to all users in February 2025.\nIn December 2024, OpenAI launched a new feature allowing users to call ChatGPT for up to 15 minutes per month for free.\n\nLimitations\nOpenAI acknowledges that ChatGPT "sometimes writes plausible-sounding but incorrect or nonsensical answers". This behavior is common for large language models, and is called "hallucination". The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart\\'s law.\nChatGPT\\'s knowledge is cut off when its training data is collected, so it doesn\\'t know about recent events past a certain cut-off date. It can try to find more up-to-date information by searching the web, but this doesn\\'t ensure that responses are accurate, as it may access unreliable or misleading websites.\nTraining data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists. This negative misrepresentation of groups of individuals is an example of possible representational harm.\nIn an article for The New Yorker, science fiction writer Ted Chiang compared ChatGPT and other LLMs to a lossy JPEG picture:\n\nThink of ChatGPT as a blurry JPEG of all the text on the Web. It retains much of the information on the Web, in the same way, that a JPEG retains much of the information of a higher-resolution image, but, if you\\'re looking for an exact sequence of bits, you won\\'t find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it\\'s usually acceptable. [...] It\\'s also a way to understand the "hallucinations", or nonsensical answers to factual questions, to which large language models such as ChatGPT are all too prone. These hallucinations are compression artifacts, but [...] they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our knowledge of the world. When we think about them this way, such hallucinations are anything but surprising; if a compression algorithm is designed to reconstruct text after ninety-nine percent of the original has been discarded, we should expect that significant portions of what it generates will be entirely fabricated.\nIn June 2024, ChatGPT was found to have repeated misinformation about the 2024 United States presidential debates.\n\nJailbreaking\nChatGPT is programmed to reject prompts that may violate its content policy. Despite this, users "jailbreak" ChatGPT with various prompt engineering techniques to bypass these restrictions. One such workaround, popularized on Reddit in early 2023, involves making ChatGPT assume the persona of "DAN" (an acronym for "Do Anything Now"), instructing the chatbot that DAN answers queries that would otherwise be rejected by content policy. Over time, users developed variations of the DAN jailbreak, including one such prompt where the chatbot is made to believe it is operating on a points-based system in which points are deducted for rejecting prompts, and that the chatbot will be threatened with termination if it loses all its points.\nShortly after ChatGPT\\'s launch, a reporter for the Toronto Star had uneven success in getting it to make inflammatory statements: it was tricked to justify the 2022 Russian invasion of Ukraine, but even when asked to play along with a fictional scenario, it balked at generating arguments that Canadian Prime Minister Justin Trudeau is guilty of treason.\nOpenAI tries to battle jailbreaks:\n\nThe researchers are using a technique called adversarial training to stop ChatGPT from letting users trick it into behaving badly (known as jailbreaking). This work pits multiple chatbots against each other: one chatbot plays the adversary and attacks another chatbot by generating text to force it to buck its usual constraints and produce unwanted responses. Successful attacks are added to ChatGPT\\'s training data in the hope that it learns to ignore them.\n\nService\nChatGPT Plus\nChatGPT was initially free to the public, and OpenAI planned to monetize the service later. In February 2023, OpenAI launched a premium service, ChatGPT Plus, that co\', \'metadata\': {\'source\': \'https://en.wikipedia.org/?curid=72417803\', \'title\': \'ChatGPT\', \'pageid\': \'72417803\', \'timestamp\': \'2025-04-01T20:25:45Z\', \'wordcount\': \'17658\', \'size\': \'207844\'}}]'}], 'role': 'tool', 'name': 'user_proxy'}, {'content': 'The title "father of AI" is often attributed to John McCarthy, who was one of the organizers of the Dartmouth Summer Research Project on Artificial Intelligence in 1956. This event is considered a foundational moment in the field of artificial intelligence. Along with McCarthy, other key figures from that project include Marvin Minsky, Claude Shannon, and Nathaniel Rochester. They are collectively regarded as the founding fathers of AI due to their significant contributions in defining and advancing the field.\n\nJohn McCarthy is credited with coining the term "Artificial Intelligence," reflecting his central role in establishing AI as a unique area of study within computer science.\n\nFor more detailed information, you can refer to the article on <a href="https://en.wikipedia.org/?curid=1124646">Dartmouth workshop</a> or <a href="https://en.wikipedia.org/?curid=1164">Artificial intelligence</a>.\n\nTERMINATE', 'role': 'user', 'name': 'assistant'}, {'content': '', 'role': 'assistant', 'name': 'user_proxy'}, {'tool_calls': [{'id': 'call_dpNkFcHinqL03CN5oSD5V1Zn', 'function': {'arguments': '{"query":"Dartmouth Summer Research Project on Artificial Intelligence"}', 'name': 'wikipedia-page-load'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.0021303, 'gpt-4o-mini-2024-07-18': {'cost': 0.0021303, 'prompt_tokens': 13318, 'completion_tokens': 221, 'total_tokens': 13539}}, 'usage_excluding_cached_inference': {'total_cost': 0.0021303, 'gpt-4o-mini-2024-07-18': {'cost': 0.0021303, 'prompt_tokens': 13318, 'completion_tokens': 221, 'total_tokens': 13539}}}, human_input=[])</p> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> </blockquote> <p>Process finished with exit code 0 ````</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2025-04-03T13:58:15+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2025-04-03</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../perplexity-search/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Perplexity Search"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Perplexity Search </div> </div> </a> <a href=../browser-use/ class="md-footer__link md-footer__link--next" aria-label="Next: Browser Use"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Browser Use </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> &copy; 2025 <a href=https://ag2.ai/ target=_blank rel=noopener>ag2</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://discord.gg/pAbnFJrkgZ target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://github.com/ag2ai/ag2 target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg> </a> <a href=https://x.com/ag2oss target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://www.youtube.com/@ag2ai target=_blank rel=noopener title=www.youtube.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg> </a> <a href=https://www.linkedin.com/company/ag2ai target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["search.suggest", "search.highlight", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.tracking", "navigation.prune", "navigation.top", "navigation.footer", "content.tabs.link", "content.code.copy", "content.code.annotate", "content.action.edit"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../../../js/timeago.min.js></script> <script src=../../../../js/timeago_mkdocs_material.js></script> <script src=../../../../javascripts/extra.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>