---
sidebarTitle: captainagent
title: agentchat.contrib.captainagent
---

## CaptainAgent

```python
class CaptainAgent(ConversableAgent)
```

(In preview) Captain agent, designed to solve a task with an agent or a group of agents.

### \_\_init\_\_

```python
def __init__(name: str,
             system_message: Optional[str] = None,
             llm_config: Optional[Union[Dict, Literal[False]]] = None,
             is_termination_msg: Optional[Callable[[Dict], bool]] = None,
             max_consecutive_auto_reply: Optional[int] = None,
             human_input_mode: Optional[str] = "NEVER",
             code_execution_config: Optional[Union[Dict,
                                                   Literal[False]]] = False,
             nested_config: Optional[Dict] = None,
             agent_lib: Optional[str] = None,
             tool_lib: Optional[str] = None,
             agent_config_save_path: Optional[str] = None,
             description: Optional[str] = DEFAULT_DESCRIPTION,
             **kwargs)
```

**Arguments**:

- `name` _str_ - agent name.
- `system_message` _str_ - system message for the ChatCompletion inference.
  Please override this attribute if you want to reprogram the agent.
- `llm_config` _dict_ - llm inference configuration.
  Please refer to [OpenAIWrapper.create](/docs/reference/oai/client#create) for available options.
- `is_termination_msg` _function_ - a function that takes a message in the form of a dictionary
  and returns a boolean value indicating if this received message is a termination message.
  The dict can contain the following keys: "content", "role", "name", "function_call".
- `max_consecutive_auto_reply` _int_ - the maximum number of consecutive auto replies.
  default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).
  The limit only plays a role when human_input_mode is not "ALWAYS".
- `agent_lib` _str_ - the path or a JSON file of the agent library for retrieving the nested chat instantiated by CaptainAgent.
- `tool_lib` _str_ - the path to the tool library for retrieving the tools used in the nested chat instantiated by CaptainAgent.
- `nested_config` _dict_ - the configuration for the nested chat instantiated by CaptainAgent.
  A full list of keys and their functionalities can be found in [docs](https://ag2ai.github.io/ag2/docs/topics/captainagent/configurations).
- `agent_config_save_path` _str_ - the path to save the generated or retrieved agent configuration.
- `**kwargs` _dict_ - Please refer to other kwargs in
  [ConversableAgent](https://github.com/ag2ai/ag2/blob/main/autogen/agentchat/conversable_agent.py#L74).

## CaptainUserProxyAgent

```python
class CaptainUserProxyAgent(ConversableAgent)
```

(In preview) A proxy agent for the captain agent, that can execute code and provide feedback to the other agents.

### \_\_init\_\_

```python
def __init__(name: str,
             nested_config: Dict,
             agent_config_save_path: str = None,
             is_termination_msg: Optional[Callable[[Dict], bool]] = None,
             max_consecutive_auto_reply: Optional[int] = None,
             human_input_mode: Optional[str] = "NEVER",
             code_execution_config: Optional[Union[Dict,
                                                   Literal[False]]] = None,
             default_auto_reply: Optional[Union[str, Dict,
                                                None]] = DEFAULT_AUTO_REPLY,
             llm_config: Optional[Union[Dict, Literal[False]]] = False,
             system_message: Optional[Union[str, List]] = "",
             description: Optional[str] = None)
```

**Arguments**:

- `name` _str_ - name of the agent.
- `nested_config` _dict_ - the configuration for the nested chat instantiated by CaptainAgent.
- `is_termination_msg` _function_ - a function that takes a message in the form of a dictionary
  and returns a boolean value indicating if this received message is a termination message.
  The dict can contain the following keys: "content", "role", "name", "function_call".
- `max_consecutive_auto_reply` _int_ - the maximum number of consecutive auto replies.
  default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).
  The limit only plays a role when human_input_mode is not "ALWAYS".
- `human_input_mode` _str_ - whether to ask for human inputs every time a message is received.
  Possible values are "ALWAYS", "TERMINATE", "NEVER".
  (1) When "ALWAYS", the agent prompts for human input every time a message is received.
  Under this mode, the conversation stops when the human input is "exit",
  or when is_termination_msg is True and there is no human input.
  (2) When "TERMINATE", the agent only prompts for human input only when a termination message is received or
  the number of auto reply reaches the max_consecutive_auto_reply.
  (3) When "NEVER", the agent will never prompt for human input. Under this mode, the conversation stops
  when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.
- `code_execution_config` _dict or False_ - config for the code execution.
  To disable code execution, set to False. Otherwise, set to a dictionary with the following keys:
  - work_dir (Optional, str): The working directory for the code execution.
  If None, a default working directory will be used.
  The default working directory is the "extensions" directory under
  "path_to_autogen".
  - use_docker (Optional, list, str or bool): The docker image to use for code execution.
  Default is True, which means the code will be executed in a docker container. A default list of images will be used.
  If a list or a str of image name(s) is provided, the code will be executed in a docker container
  with the first image successfully pulled.
  If False, the code will be executed in the current environment.
  We strongly recommend using docker for code execution.
  - timeout (Optional, int): The maximum execution time in seconds.
  - last_n_messages (Experimental, Optional, int): The number of messages to look back for code execution. Default to 1.
- `default_auto_reply` _str or dict or None_ - the default auto reply message when no code execution or llm based reply is generated.
- `llm_config` _dict or False_ - llm inference configuration.
  Please refer to [OpenAIWrapper.create](/docs/reference/oai/client#create)
  for available options.
  Default to false, which disables llm-based auto reply.
- `system_message` _str or List_ - system message for ChatCompletion inference.
  Only used when llm_config is not False. Use it to reprogram the agent.
- `description` _str_ - a short description of the agent. This description is used by other agents
  (e.g. the GroupChatManager) to decide when to call upon this agent. (Default: system_message)

